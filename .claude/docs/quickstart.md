# Quick Start Guide

## Prerequisites

- Python 3.12
- Qdrant vector database running on port 6333
- OpenAI API key

## Setup Steps

### 1. Clone & Navigate

```bash
cd "/Users/jesse/PycharmProjects/RAG BBL KOV/rag-app"
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment (if not exists)
python3.12 -m venv venv

# Activate venv
source venv/bin/activate  # Mac/Linux
# OR
venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### 3. Start Qdrant

```bash
# Option 1: Docker
docker run -p 6333:6333 qdrant/qdrant

# Option 2: Docker Compose (if available)
docker-compose up -d qdrant
```

### 4. Start Backend

```bash
cd backend
./venv/bin/python main.py

# Should see:
# INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 5. Frontend Setup

```bash
# In new terminal
cd frontend

# Create virtual environment
python3.12 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit if needed (default: BACKEND_URL=http://localhost:8000)
```

### 6. Start Frontend

```bash
cd frontend
streamlit run app.py

# Should open browser at http://localhost:8501
```

## First Steps

### 1. Register Account

- Open http://localhost:8501
- Click "Register"
- Create account with email, username, password

### 2. Login

- Use credentials from registration
- JWT token stored in session

### 3. Upload Document

- Go to "Document Management" page
- Upload PDF or text file
- Wait for processing (shows progress)

### 4. Query Documents

- Go to "Query" page
- Enter question: "Wat zijn de eisen voor BBL?"
- View answer + sources

### 5. Chat Session (Optional)

- Go to "Chat" page
- Create new session
- Ask follow-up questions with context

## Testing

```bash
cd backend

# Run all tests
pytest -v

# Run specific test file
pytest test_auth.py -v

# Run with coverage
pytest --cov=. --cov-report=html
```

## Troubleshooting

### Backend won't start

**Error**: `OPENAI_API_KEY must be set`
```bash
# Check .env file
cat backend/.env | grep OPENAI_API_KEY

# Should NOT be: OPENAI_API_KEY=your-api-key-here
# Should be: OPENAI_API_KEY=sk-...actual-key...
```

**Error**: `Connection refused to Qdrant`
```bash
# Check if Qdrant is running
curl http://localhost:6333

# Start Qdrant
docker run -p 6333:6333 qdrant/qdrant
```

**Error**: `ModuleNotFoundError`
```bash
# Activate venv first
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

### Frontend won't connect

**Error**: `Connection refused to backend`
```bash
# Check backend is running
curl http://localhost:8000/health

# Check frontend .env
cat frontend/.env | grep BACKEND_URL
# Should be: BACKEND_URL=http://localhost:8000
```

### Slow queries

**Check**: Performance optimizations active?
```bash
# Check backend logs
tail -f backend/backend_optimized.log

# Should see:
# INFO:rag.llm.openai_provider:LLM model: gpt-4-turbo  # NOT gpt-5!
# INFO:cache:Cache HIT for query: ...  # For repeat queries
```

**Expected times**:
- First query: 4-8 seconds
- Cached query: <0.1 seconds
- If seeing 25-47s: check model is gpt-4-turbo not gpt-5

### Permission denied

```bash
# Mac security - allow python to access files
# System Preferences → Security & Privacy → Files and Folders

# Or run from terminal with permissions
cd backend
python main.py  # Not ./venv/bin/python if permission issue
```

## Common Commands

```bash
# Backend
cd backend
./venv/bin/python main.py              # Start server
pytest -v                               # Run tests
tail -f backend_optimized.log           # View logs

# Frontend
cd frontend
streamlit run app.py                    # Start UI
streamlit run app.py --server.port 8502 # Custom port

# Database
sqlite3 backend/bbl_rag_app.db          # Open DB
.tables                                 # List tables
SELECT * FROM users;                    # Query users

# Qdrant
curl http://localhost:6333/collections  # List collections
curl http://localhost:6333/health       # Health check

# Clean restart
rm backend/bbl_rag_app.db               # Reset database
# Restart Qdrant container (resets vectors)
```

## Environment Variables Reference

### Backend `.env`

```bash
# Required
OPENAI_API_KEY=sk-...           # Your OpenAI API key

# Optional (have defaults)
JWT_SECRET_KEY=<auto-generated>  # JWT signing key
DATABASE_URL=sqlite:///./bbl_rag_app.db
QDRANT_HOST=localhost
QDRANT_PORT=6333
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
CORS_ORIGINS=http://localhost:8501,http://localhost:3000

# Model config
OPENAI_LLM_MODEL=gpt-4-turbo
OPENAI_EMBED_MODEL=text-embedding-3-large

# RAG config
CHUNK_SIZE=1200
CHUNK_OVERLAP=200
SIMILARITY_THRESHOLD=0.7
DEFAULT_TOP_K=3
MAX_TOP_K=10
MAX_FILE_SIZE_MB=10
```

### Frontend `.env`

```bash
BACKEND_URL=http://localhost:8000
```

## Development Workflow

### Making changes

```bash
# 1. Edit code
vim backend/rag/pipeline.py

# 2. Run tests
pytest test_rag.py -v

# 3. Restart backend (Ctrl+C, then restart)
./venv/bin/python main.py

# 4. Test via frontend or curl
curl -X POST http://localhost:8000/api/query \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 3}'
```

### Git workflow

```bash
# Check status
git status

# Stage changes
git add backend/rag/pipeline.py
git add backend/cache.py

# Commit
git commit -m "feat: add query caching with LRU eviction"

# Push
git push origin main

# Note: .env files are gitignored (security)
```

## Next Steps

- Read [Architecture](./architecture.md) for system overview
- Read [Backend Structure](./backend-structure.md) for code organization
- Read [Performance](./performance.md) for optimization details
- Read [API Endpoints](./api-endpoints.md) for endpoint documentation

## Getting Help

- Check logs: `tail -f backend/backend_optimized.log`
- Test health: `curl http://localhost:8000/health`
- View API docs: http://localhost:8000/docs (FastAPI Swagger UI)
- Read tests: `backend/test_*.py` for usage examples
